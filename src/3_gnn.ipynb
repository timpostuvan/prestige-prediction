{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from exploration.dataset import PyGAcademicGraph\n",
    "\n",
    "from utils import train, evaluate\n",
    "\n",
    "from exploitation.models import GAT, GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the train dataset:  9\n",
      "Number of samples in the val dataset:  9\n",
      "Number of samples in the test dataset:  9\n",
      "Output of one sample from the train dataset:  Data(edge_index=[2, 36936], y=[359], x=[359, 8], edge_attr=[36936, 3], domain='Academia', train_mask=[359], val_mask=[359], test_mask=[359], mask=[359])\n",
      "Edge_index :\n",
      "tensor([[  0,   0,   0,  ..., 357, 358, 358],\n",
      "        [  1,  89, 121,  ..., 352,  89, 358]])\n",
      "Number of features per node:  8\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# train dataset\n",
    "train_dataset = PyGAcademicGraph(split=\"train\", setting=\"transductive\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "# val dataset\n",
    "val_dataset = PyGAcademicGraph(split=\"val\", setting=\"transductive\")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = PyGAcademicGraph(split=\"test\", setting=\"transductive\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# number of features\n",
    "n_features = train_dataset[0].x.shape[1]\n",
    "\n",
    "print(\"Number of samples in the train dataset: \", len(train_dataset))\n",
    "print(\"Number of samples in the val dataset: \", len(test_dataset))\n",
    "print(\"Number of samples in the test dataset: \", len(test_dataset))\n",
    "print(\"Output of one sample from the train dataset: \", train_dataset[0])\n",
    "print(\"Edge_index :\")\n",
    "print(train_dataset[0].edge_index)\n",
    "print(\"Number of features per node: \", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"\\nDevice: \", device)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "graph_convolution_no_weights = GCN(\n",
    "    input_size=n_features,\n",
    "    hidden_size=256,\n",
    "    output_size=1,\n",
    "    num_layers=2,\n",
    "    heads=3).to(device)\n",
    "\n",
    "loss_fcn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(graph_convolution_no_weights.parameters(), lr=0.005)\n",
    "\n",
    "epoch_list, GCN_MSE = train(graph_convolution_no_weights, loss_fcn, device, optimizer, num_epochs, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"\\nDevice: \", device)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "graph_convolution_no_weights = GCN(\n",
    "    input_size=n_features,\n",
    "    hidden_size=256,\n",
    "    output_size=1,\n",
    "    num_layers=2,\n",
    "    heads=3).to(device)\n",
    "\n",
    "loss_fcn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(graph_convolution_no_weights.parameters(), lr=0.005)\n",
    "\n",
    "epoch_list, GCN_MSE = train(graph_convolution_no_weights, loss_fcn, device, optimizer, num_epochs, train_dataloader, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
